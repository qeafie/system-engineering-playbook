# Архитектурные Решения (ADR) для Системы Первичного HR-Скрининга

## ADR-001: Выбор архитектурного стиля — Микросервисы с Event-Driven на Apache Kafka

**Решение**: Принята микросервисная архитектура с шиной событий Apache Kafka. Компоненты системы разделены на функциональные модули, взаимодействующие через асинхронные сообщения.

### Обоснование:
1. **Обработка видеопотока в реальном времени**: Модуль AI-интервьюера должен обрабатывать медиаданные с задержкой менее 2 секунд. Выделенный микросервис для медиа (WebRTC SFU) может масштабироваться горизонтально независимо от других компонентов.
   
2. **Генерация адаптивных вопросов**: Модуль вопросов, основанный на ollama + qwen3, требует значительных вычислительных ресурсов (GPU). Микросервисная архитектура позволяет развертывать его на отдельном GPU-кластере и масштабировать по количеству активных сессий.

3. **Надежность и журналирование операций с ПДн**: Модуль безопасности и соответствия 152-ФЗ должен гарантированно фиксировать все события, связанные с персональными данными. Event-driven подход с Kafka обеспечивает гарантированную доставку и сохранение этих событий для последующего аудита.

4. **Горизонтальная масштабируемость**: Требование поддерживать до 100 одновременных сессий делает монолитную архитектуру неэффективной. Микросервисы позволяют добавлять инстансы только тех компонентов, которые испытывают нагрузку (например, модули анализа эмоций pyAudioAnalysis и EmotiEffLib).

5. **Процесс работы из технического задания**: Шаги системы (получение согласия → проведение интервью → анализ → генерация отчета → решение HR) естественным образом ложатся на цепочку взаимодействующих сервисов. Kafka выступает в роли клея, передавая данные о завершении одного этапа для начала следующего.

---

## ADR-002: Выбор моделей и технологий искусственного интеллекта

**Решение**: Применен гибридный стек AI-технологий с локальным развертыванием:

- **Распознавание речи**: Whisper (MIT license).
- **Анализ эмоций**: pyAudioAnalysis (8 базовых эмоций) в связке с EmotiEffLib (43 параметра микровыражений).
- **Генерация адаптивных вопросов**: Модель qwen3, развернутая через фреймворк ollama.

### Обоснование:

1. **Для модуля распознавания речи (Whisper)**:
   - **Точность и поддержка языков**: Показатель точности >95% на русском языке соответствует заявленным требованиям. Поддержка множества языков позволяет работать с международными кандидатами.
   - **Лицензия и локализация**: MIT-лицензия разрешает коммерческое использование. Модель может быть развернута на собственном GPU-оборудовании внутри периметра инфраструктуры заказчика, что является обязательным условием для обработки персональных данных (видео/аудио интервью) по 152-ФЗ.
   - **Производительность**: Оптимизирована для трансформаторной архитектуры, что позволяет достичь требуемой скорости обработки потока.

2. **Для модуля анализа эмоций (pyAudioAnalysis + EmotiEffLib)**:
   - **Комплексный анализ**: Комбинация библиотек закрывает все требования: pyAudioAnalysis дает общую оценку по базовым эмоциям (радость, грусть, злость и т.д.) с точностью 82%, а EmotiEffLib предоставляет детализированный анализ микровыражений (коротких, непроизвольных движений лица), что является сильным индикатором искренности.
   - **Научная обоснованность**: EmotiEffLib основана на системе кодирования лицевых движений (FACS), что повышает доверие к результатам анализа со стороны HR-специалистов.
   - **Открытый исходный код**: Возможность доработки и адаптации моделей под специфические корпоративные сценарии.

3. **Для модуля генерации вопросов (ollama + qwen3)**:
   - **Контекстная память 8000 токенов**: Модель qwen3 поддерживает достаточно длинный контекст, чтобы "помнить" все предыдущие ответы кандидата в рамках 20-минутного интервью и строить уточняющие вопросы.
   - **Оценка 15+ компетенций**: LLM-модель способна анализировать текстовую транскрипцию ответа на предмет проявления конкретных компетенций (лидерство, работа в команде, аналитическое мышление) и генерировать следующий вопрос для более глубокой проверки.
   - **Контроль и безопасность**: Локальное развертывание через ollama исключает утечку вопросов и ответов к сторонним провайдерам, обеспечивая полный контроль над данными. Это критически важно, так как в ответах могут раскрываться коммерческие тайны или иная чувствительная информация.

---

## ADR-003: Выбор стратегии хранения данных

**Решение**: Применена полиглотная архитектура хранения, где каждый тип данных обслуживается оптимальной для него системой:

- **PostgreSQL** — для структурированных транзакционных данных.
- **MinIO (S3-совместимое хранилище)** — для больших бинарных объектов (видео).
- **Redis** — для кэширования и хранения состояний в реальном времени.
- **Elasticsearch** — для индексации, поиска и анализа логов.

### Обоснование для каждого хранилища:

1. **Для структурированных данных (PostgreSQL)**:
   - **ACID-транзакции и надежность**: Обработка цифровых согласий на ПДн с электронной подписью (ГОСТ Р 34.10-2012) является юридически значимой операцией. Требуется гарантированная запись, целостность и консистентность данных, что обеспечивает PostgreSQL.
   - **Сложные запросы и связи**: HR-интерфейсу необходимы сложные выборки, джойны и агрегации для фильтрации кандидатов, построения отчетов по вакансиям. Реляционная модель PostgreSQL идеально подходит для этого.
   - **Поддержка JSONB**: Позволяет гибко хранить структурированные отчеты AI (оценки по компетенциям, эмоциональные профили) внутри реляционных таблиц, сочетая строгость схемы с гибкостью NoSQL.

2. **Для видеоданных (MinIO)**:
   - **Объем и характер данных**: Одна сессия интервью (20 минут, 1080p) занимает ~2 ГБ. При 100 сессиях в день объем хранения растет на 200 ГБ/день. Объектное хранилище эффективно и экономично для таких объемов.
   - **Надежность и доступность**: MinIO обеспечивает отказоустойчивость через erasure coding, географическую репликацию для Disaster Recovery, что критично для сохранности персональных данных.
   - **Интеграция и шифрование**: S3-совместимый API упрощает интеграцию. Поддерживает шифрование данных на стороне сервера (SSE), что является требованием для защиты ПДн по 152-ФЗ.

3. **Для данных реального времени (Redis)**:
   - **Скорость доступа**: Текущее состояние сессии (последний заданный вопрос, накопленный контекст для LLM, метрики качества связи) должно быть доступно с латенси менее 10 мс для обеспечения плавного диалога.
   - **Временные данные**: Сессии интервью имеют ограниченный срок жизни (минуты/часы). Redis с TTL (time-to-live) идеально подходит для таких данных, автоматически очищая память.
   - **Механизм Pub/Sub**: Используется для рассылки уведомлений HR-менеджерам о новых отчетах через WebSocket, что соответствует требованию swipe-интерфейса для быстрого принятия решений.

4. **Для логов и поиска (Elasticsearch)**:
   - **Требования к журналированию**: 152-ФЗ обязывает вести журнал всех операций с персональными данными. Elasticsearch позволяет индексировать миллионы логов и выполнять быстрый полнотекстовый и структурированный поиск для внутреннего аудита или запросов от регулятора.
   - **Аналитика и мониторинг**: Kibana поверх Elasticsearch позволяет строить дашборды для мониторинга метрик производительности (uptime 99.5%, время генерации отчета) и бизнес-показателей (конверсия кандидатов).

---

## ADR-004: Выбор брокера сообщений и механизмов межсервисного взаимодействия

**Решение**: Использована многоуровневая система коммуникаций:

- **Apache Kafka** — как основная шина событий (event bus) для потоковой обработки и гарантированной доставки.
- **gRPC** — для низколатентного RPC-взаимодействия между внутренними сервисами.
- **REST/GraphQL** — для публичного API и интеграций.
- **WebRTC** — для передачи медиапотоков от клиента.
- **WebSocket** — для push-уведомлений в HR-интерфейс.

### Обоснование:

1. **Для событийной шины (Apache Kafka)**:
   - **Обработка потока видеоданных**: Kafka способен поглощать высокоскоростной поток сообщений (кадры видео, аудиосэмплы) от медиасервера и распределять их по потребителям — сервисам распознавания речи и анализа эмоций.
   - **Гарантированный порядок и доставка**: События в рамках одной сессии интервью должны быть обработаны в строгом порядке. Гарантии доставки и порядок внутри партиции Kafka критичны для контекстной логики диалога.
   - **Журнал событий для аудита**: Все значимые действия (подписание согласия, начало/конец интервью, доступ HR к отчету) публикуются в Kafka для последующего аудита.

2. **Для внутренних RPC-вызовов (gRPC)**:
   - **Производительность и эффективность**: Взаимодействие между сервисами требует минимальной задержки и высокой пропускной способности. Протокол gRPC значительно эффективнее текстового REST/JSON.
   - **Поддержка потоковой передачи**: Позволяет передавать данные анализа от AI-сервисов к сервису отчетности в реальном времени.

3. **Для внешних интеграций (REST/GraphQL)**:
   - **Интеграция с ATS**: Эти системы ожидают взаимодействия по стандартным REST API. GraphQL предлагается для продвинутых клиентов, позволяя запрашивать именно те данные, которые нужны.

4. **Для медиакоммуникаций (WebRTC)**:
   - WebRTC является лучшим решением для передачи видео и аудио с камеры в браузере с минимальной задержкой.

5. **Для уведомлений UI (WebSocket)**:
   - **Swipe-интерфейс для HR**: Для мгновенного обновления списка кандидатов и уведомлений используется WebSocket.

---

### Итоги

Представленный набор архитектурных решений формирует основу для системы, которая:

- Выполняет функциональные требования: Обеспечивает проведение AI-интервью с анализом речи, эмоций и генерацией адаптивных вопросов.
- Соответствует нефункциональным требованиям: Достигает производительности (100 одновременных сессий, отчет за <5 мин), надежности (99.5% uptime, ACID) и безопасности (152-ФЗ "из коробки").
- Обеспечивает масштабируемость и гибкость: Микросервисная архитектура с полиглотным хранением и event-driven взаимодействием позволяет системе расти и адаптироваться к новым требованиям.

---
